## Работа с большим объёмом реальных данных
1. Создадим базу данных в Postgres:
```
sudo -u postgres psql
create database taxi;
\c taxi;
```
2. Создадим таблицу для загрузки данных:
```
create table taxi_trips (
unique_key text, 
taxi_id text, 
trip_start_timestamp TIMESTAMP, 
trip_end_timestamp TIMESTAMP, 
trip_seconds bigint, 
trip_miles numeric, 
pickup_census_tract bigint, 
dropoff_census_tract bigint, 
pickup_community_area bigint, 
dropoff_community_area bigint, 
fare numeric, 
tips numeric, 
tolls numeric, 
extras numeric, 
trip_total numeric, 
payment_type text, 
company text, 
pickup_latitude numeric, 
pickup_longitude numeric, 
pickup_location text, 
dropoff_latitude numeric, 
dropoff_longitude numeric, 
dropoff_location text
);
```

3. Создадим и запустим bash-скрипт для загрузки данных в Postgresql:
```
#!/bin/bash

for f in /home/user/taxi/taxi*
do
        echo -e "Processing $f file..."
        psql "localhost port=5432 dbname=taxi user=postgres " -c "\\COPY taxi_trips FROM PROGRAM 'cat $f' CSV HEADER"
done
```

4. Проверим, что данные успешно загрузились:
```
taxi=# \l+ taxi
                                                                       Список баз данных
 Имя  | Владелец | Кодировка | Провайдер локали | LC_COLLATE  |  LC_CTYPE   | локаль ICU | Правила ICU | Права доступа | Размер | Табл. пространство | Описание
------+----------+-----------+------------------+-------------+-------------+------------+-------------+---------------+--------+--------------------+----------
 taxi | postgres | UTF8      | libc             | ru_RU.UTF-8 | ru_RU.UTF-8 |            |             |               | 11 GB  | pg_default         |

```

5. Включить секундомер:
```
\timing
```

6. Выполним запрос:
```
SELECT payment_type, 
    round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, 
    count(*) as c
FROM taxi_trips
group by payment_type
order by 3;
```
Результат:
```
 71072,521 мс (01:11,073)
```
Время выполнения запроса составило 71 секунду.

7. Установим и запустим ClickHouse:
```
sudo apt install clickhouse-server clickhouse-client
sudo systemctl start clickhouse-server
```

8. Создадим папки для конфигурации:
```
sudo mkdir -p /etc/clickhouse-server/{config.d,users.d}
```

9. Создадим файлы конфигурации:
```
sudo nano /etc/clickhouse-server/config.d/listen.xml

<?xml version="1.0"?>

<clickhouse>
    <listen_host>0.0.0.0</listen_host>
</clickhouse>
```

```
sudo nano /etc/clickhouse-server/users.d/dbuser.xml

<?xml version="1.0"?>

<clickhouse>
    <users>
    <myuser>
        <password>mypass</password>
        <networks>
            <ip>::/0</ip>
    </networks>
        <profile>default</profile>
        <quota>default</quota>
        <allow_databases>
      <database>taxi</database>
        </allow_databases>
    </myuser>
    </users>
</clickhouse>
```

10. Создадим базу данных:
```
clickhouse-client
create database taxi;
use taxi;
```
11. Создадим таблицу:
```
CREATE TABLE taxi.taxi_trips(
    `unique_key` String,
    `taxi_id` String,
    `trip_start_timestamp` Datetime,
    `trip_end_timestamp` DateTime,
    `trip_seconds` Int64,
    `trip_miles` Float64,
    `pickup_census_tract` Int64,
    `dropoff_census_tract` Int64,
    `pickup_community_area` Int64,
    `dropoff_community_area` Int64,
    `fare` Float64,
    `tips` Float64,
    `tolls` Float64,
    `extras` Float64,
    `trip_total` Float64,
    `payment_type` String,
    `company` String,
    `pickup_latitude` Float64,
    `pickup_longitude` Float64,
    `pickup_location` String,
    `dropoff_latitude` Float64,
    `dropoff_longitude` Float64,
    `dropoff_location` String
)
ENGINE = MergeTree()
ORDER BY taxi_id;
```
12. Загрузим данные скриптом:
```
#!/bin/bash
for f in /home/user/taxi/taxi*
do
  echo -e "Processing $f file...";
    sed -i 's/UTC//g' $f;
  clickhouse-client -h localhost --port 9000 --user=myuser --password mypass -d taxi -q "INSERT INTO taxi_trips FORMAT CSVWithNames" <  $f;
done;
```
13. Выполним запрос, аналогичный выполненному в PostgreSQL:
```
SELECT payment_type, 
    round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, 
    count(*) as c
FROM taxi_trips
group by payment_type
order by c;
```
Результат:
```
11 rows in set. Elapsed: 0.391 sec. Processed 21.05 million rows, 656.35 MB (53.88 million rows/s., 1.68 GB/s.)
```
14. Вывод: в ClickHouse время выполнения запроса составило 0.391 секунды, а в PostgreSQL 71 секунду, что примерно в 181 раз дольше, чем в ClickHouse.